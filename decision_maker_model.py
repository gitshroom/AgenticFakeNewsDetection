# -*- coding: utf-8 -*-
"""Decision-Maker Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13h3TY8t_2cPOAWSv1zJ2NGxFYIET2OZc
"""

import json
import os
from typing import List, Optional, Any

# --- Configuration ---
# Define the expected filename for the input JSON data.
INPUT_FILENAME = "henrich_cheni.json"
# Define the filename for the output JSON data.
OUTPUT_FILENAME = "decision_summary.json"

# ---------------------------------------------------
## üìú Core Data Classes (Modified: Removed Credibility)

class Evidence:
    """
    Represents a single piece of evidence with its weighted characteristics.
    """
    def __init__(self,
                 stance: int,          # Si ‚àà {-1, 0, +1}
                 confidence: float,    # Confi
                 quality: Optional[float] = 1.0,  # Qi
                 recency_weight: Optional[float] = 1.0):  # wT
        self.stance = stance
        self.confidence = confidence
        self.quality = quality
        self.recency_weight = recency_weight

    def weighted_score(self) -> float:
        """
        Compute the per-evidence weighted score: Ei = Si √ó Confi √ó Qi √ó wT
        (Credibility Ci is removed from the formula)
        """
        return (self.stance *
                self.confidence *
                self.quality *
                self.recency_weight)
# ---------------------------------------------------
class DecisionMaker:
    """
    Aggregates evidence to compute a Claim Truth Score (CTS)
    and determines the final decision (True, Fake, Unknown).
    """
    def __init__(self, evidence_items: List[Evidence]):
        self.evidence_items = evidence_items

    def compute_cts(self) -> float:
        """
        Compute the Claim Truth Score (CTS): CTS = Œ£(Ei)
        (Normalization by Œ£(Ci) is removed)
        """
        # CTS is now the total sum of weighted scores (Ei)
        total_weighted = sum(e.weighted_score() for e in self.evidence_items)
        return total_weighted

    def decision(self) -> tuple[str, float]:
        """
        Translate CTS into discrete decisions.
        """
        cts = self.compute_cts()

        # Simplified decision logic based only on score thresholds
        if cts >= 0.3:
            verdict = "True"
        elif cts <= -0.3:
            verdict = "Fake"
        else:
            verdict = "Unknown"

        return verdict, cts

# ---------------------------------------------------
## üìñ JSON Reading and Parsing Functions

def read_evidence_data(filename: str) -> List[Any]:
    """
    Reads and parses a JSON file containing the evidence list.
    MODIFIED: Expects the evidence list directly at the root level.
    """
    if not os.path.exists(filename):
        print(f"‚ùå ERROR: The input file '{filename}' was not found.")
        return []

    try:
        with open(filename, 'r') as file:
            data = json.load(file)

            # Check if the root element is a list
            if isinstance(data, list):
                print(f"‚úÖ Input read successfully from '{filename}'.")
                return data
            else:
                print(f"‚ùå ERROR: Root element of JSON must be a list of evidence records.")
                return []

    except json.JSONDecodeError as e:
        print(f"‚ùå ERROR: Failed to parse JSON data in '{filename}'. Check file format. Error: {e}")
        return []
    except Exception as e:
        print(f"‚ùå General File Error: {e}")
        return []

def parse_evidence_records(records: List[Any]) -> List[Evidence]:
    """
    Converts a list of raw dictionaries into a list of Evidence objects.
    (Removed access to Source Credibility)
    """
    evidence_list = []

    # Mapping the string stance from JSON to the required integer stance for the Evidence class
    stance_map = {"support": 1, "neutral": 0, "contradiction": -1}

    for record in records:
        try:
            # We must map the string stance from the JSON to the integer stance
            raw_stance = record.get("Predicted Stance", "neutral").lower()

            new_evidence = Evidence(
                # Removed credibility = record["Source Credibility"],
                stance = stance_map.get(raw_stance, 0), # Default to 0 (Neutral) if stance is missing/invalid
                confidence = record["Model Confidence"],
                quality = record.get("Quality Score", 1.0),
                recency_weight = record.get("Recency Weight", 1.0)
            )
            evidence_list.append(new_evidence)

        except KeyError as e:
            # The only expected KeyError now is if "Model Confidence" or "Predicted Stance" is missing
            print(f"‚ö†Ô∏è Warning: Skipping evidence record due to missing required key: {e}. Check for 'Model Confidence' or 'Predicted Stance'.")
        except TypeError as e:
            print(f"‚ö†Ô∏è Warning: Skipping evidence record due to invalid data type: {e}")

    return evidence_list

# ---------------------------------------------------
## üíæ JSON Output Writer Function (NEW)

def write_decision_to_file(decision_summary: dict, filename: str):
    """
    Writes the final decision dictionary to a specified JSON file.
    """
    try:
        with open(filename, 'w') as file:
            json.dump(decision_summary, file, indent=4)
        print(f"‚úÖ Decision successfully written to '{filename}'.")
    except Exception as e:
        print(f"‚ùå Error writing output file: {e}")

# ---------------------------------------------------
## üöÄ Main Execution Block

if __name__ == "__main__":

    print(f"Starting Decision Maker with input file: {INPUT_FILENAME}")

    # 1. Read the JSON file and extract the records list
    raw_evidence_records = read_evidence_data(INPUT_FILENAME)

    if not raw_evidence_records:
        print("üõë Exiting due to no valid evidence data.")
        exit(1)

    # 2. Parse the records into Evidence objects
    evidence_objects = parse_evidence_records(raw_evidence_records)

    if not evidence_objects:
        print("üõë Exiting due to no valid Evidence objects created.")
        exit(1)

    # 3. Run the Decision Maker Model
    decision_maker = DecisionMaker(evidence_objects)
    final_verdict, cts = decision_maker.decision()

    # 4. Construct Output Summary
    final_decision_summary = {
        "verdict": final_verdict,
        "claim_truth_score": round(cts, 4),
        "evidence_count": len(evidence_objects),
        "input_file": INPUT_FILENAME
    }

    # 5. Console Output
    print("\n--- Final Claim Veracity Decision ---")
    print(f"Total Evidence Items Processed: {len(evidence_objects)}")
    print(f"Claim Truth Score (CTS): {cts:.4f}")
    print(f"Final Decision: **{final_verdict.upper()}**")
    print("-------------------------------------")

    # 6. Write Result to JSON File
    write_decision_to_file(final_decision_summary, OUTPUT_FILENAME)
